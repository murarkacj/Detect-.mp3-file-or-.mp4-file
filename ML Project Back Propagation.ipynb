{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4781b224",
   "metadata": {},
   "source": [
    "# <center>Shri Ramdeobaba College of Engineering and Management , Nagpur</center>\n",
    "### <center>Subject Name : Machine Learning</center>\n",
    "### <center>Assignment : TA-1</center>\n",
    "### Student Name\n",
    "#### 1.) Chaitanya Murarka , E-35\n",
    "#### 2.) Alkesh Tripathi , E-28\n",
    "#### 3.) Shweta Mishra , E-19\n",
    "#### 4.) Harsha Hargunani , E-09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c28581",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "This definition include: gather some .mp3 and .mp4 files around 1000.\n",
    "Consider 90% of data as a training data and 10% of data as a test data.\n",
    "Convert those files into features matrix. Apply backpropagation neural\n",
    "network to learn whether these are .mp3 or .mp4 files. Plot training and\n",
    "testing accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aff259c",
   "metadata": {},
   "source": [
    "## Assignment Phases\n",
    "### 1. Data Preprocessing\n",
    "### 2. Defining our model and training\n",
    "### 3. Testing our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c65bad9",
   "metadata": {},
   "source": [
    "## Step 1.) Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f5c5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries to be used\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import matplotlib.pyplot as plt\n",
    "from tinytag import TinyTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd0f57a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"album\": null, \"albumartist\": null, \"artist\": null, \"audio_offset\": 45, \"bitrate\": 48.0, \"channels\": 1, \"comment\": null, \"composer\": null, \"disc\": null, \"disc_total\": null, \"duration\": 5.090666666666667, \"extra\": {}, \"filesize\": 30717, \"genre\": null, \"samplerate\": 32000, \"title\": null, \"track\": null, \"track_total\": null, \"year\": null}, {\"album\": null, \"albumartist\": null, \"artist\": null, \"audio_offset\": 45, \"bitrate\": 48.0, \"channels\": 1, \"comment\": null, \"composer\": null, \"disc\": null, \"disc_total\": null, \"duration\": 5.666666666666667, \"extra\": {}, \"filesize\": 34173, \"genre\": null, \"samplerate\": 32000, \"title\": null, \"track\": null, \"track_total\": null, \"year\": null}, {\"album\": null, \"albumartist\": null, \"artist\": null, \"audio_offset\": 45, \"bitrate\": 48.0, \"channels\": 1, \"comment\": null, \"composer\": null, \"disc\": null, \"disc_total\": null, \"duration\": 3.7586666666666666, \"extra\": {}, \"filesize\": 22725, \"genre\": null, \"samplerate\": 32000, \"title\": null, \"track\": null, \"track_total\": null, \"year\": null}, {\"album\": null, \"albumartist\": null, \"artist\": null, \"audio_offset\": 45, \"bitrate\": 48.0, \"channels\": 1, \"comment\": null, \"composer\": null, \"disc\": null, \"disc_total\": null, \"duration\": 7.286666666666667, \"extra\": {}, \"filesize\": 43893, \"genre\": null, \"samplerate\": 32000, \"title\": null, \"track\": null, \"track_total\": null, \"year\": null}]\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty list named file to store the features of our files from TinyTag\n",
    "# We have 808 .mp3 files and 192 .mp4 files\n",
    "file = [None]*1000\n",
    "for i in range(500):\n",
    "    file[i] = TinyTag.get(r'clips\\\\'+'dhwani'+str(i)+'.mp3')\n",
    "for i in range(500,808):\n",
    "    file[i] = TinyTag.get(r'audio_data_2\\\\'+'dhwani'+str(i)+'.mp3')\n",
    "for i in range(808,1000):\n",
    "    j = i - 808\n",
    "    file[i] = TinyTag.get(r'video\\\\'+'video'+str(j)+'.mp4')\n",
    "print(file[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b680a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X : <class 'numpy.ndarray'>\n",
      "y : <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# We desire to have our data of features in array format\n",
    "# X contains the features in order size/duration , samplerate , audio_offset , bitrate\n",
    "# y contains 1 for .mp3 files and 0 for .mp4 files\n",
    "feature = [None]*1000\n",
    "for i in range(1000):\n",
    "    data1 = (file[i].filesize/file[i].duration)\n",
    "    data2 = file[i].samplerate\n",
    "    # audio_offset\n",
    "    if file[i].audio_offset == None:\n",
    "        data3 = 0\n",
    "    else:\n",
    "        data3 = file[i].audio_offset   \n",
    "    # bitrate\n",
    "    if file[i].bitrate == 'None':\n",
    "        data4 = 0\n",
    "    else:\n",
    "        data4 = file[i].bitrate\n",
    "    feature[i] = [data1,data2,data3,data4]\n",
    "X = np.array(feature)\n",
    "print(\"X :\",type(X))\n",
    "output = [None]*1000\n",
    "for i in range(808):\n",
    "    output[i] = [1]\n",
    "for i in range(808,1000):\n",
    "    output[i] = [0]\n",
    "y = np.array(output)\n",
    "print(\"y :\",type(y))\n",
    "# clearing the variables since they wouldn't be need further\n",
    "del feature\n",
    "del file\n",
    "del output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ec36447",
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = X / np.amax(X,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6deac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test data\n",
    "# 10% testing data is required so test_size = 100\n",
    "# random state is the random data selection of our X and y into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240a66df",
   "metadata": {},
   "source": [
    "## Step 2.) Defining our Back-Propagation model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08f7c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "learning_rate = 0.1\n",
    "iterations = 3000\n",
    "N = y_train.size\n",
    "\n",
    "# number of input features\n",
    "input_size = 4\n",
    "\n",
    "# number of hidden layers neurons\n",
    "hidden_size = 4 \n",
    "\n",
    "# number of neurons at the output layer\n",
    "output_size = 1  \n",
    "\n",
    "results = pd.DataFrame(columns=[\"mse\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bab859c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "np.random.seed(10)\n",
    "\n",
    "# initializing weight for the hidden layer\n",
    "W1 = np.random.normal(scale=0.5, size=(input_size, hidden_size))   \n",
    "\n",
    "# initializing weight for the output layer\n",
    "W2 = np.random.normal(scale=0.5, size=(hidden_size , output_size)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "323248b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def mean_squared_error(y_pred, y_true):\n",
    "    return ((y_pred - y_true)**2).sum() / (2*y_pred.size)\n",
    "    \n",
    "def accuracy(y_pred, y_true):\n",
    "    acc = y_pred.argmax(axis=1) == y_true.argmax(axis=1)\n",
    "    return acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "721fcd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for itr in range(iterations):    \n",
    "    \n",
    "    # feedforward propagation\n",
    "    # on hidden layer\n",
    "    Z1 = np.dot(X_train, W1)\n",
    "    A1 = sigmoid(Z1)\n",
    "\n",
    "    # on output layer\n",
    "    Z2 = np.dot(A1, W2)\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    # backpropagation\n",
    "    E1 = A2 - y_train\n",
    "    dW1 = E1 * A2 * (1 - A2)\n",
    "\n",
    "    E2 = np.dot(dW1, W2.T)\n",
    "    dW2 = E2 * A1 * (1 - A1)\n",
    "\n",
    "    \n",
    "    # weight updates\n",
    "    W2_update = np.dot(A1.T, dW1) / N\n",
    "    W1_update = np.dot(X_train.T, dW2) / N\n",
    "\n",
    "    W2 = W2 - learning_rate * W2_update\n",
    "    W1 = W1 - learning_rate * W1_update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25de6bc9",
   "metadata": {},
   "source": [
    "## Step 3.) Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4adce684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meaned Squared Error : 0.03943592983850345\n",
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "# feedforward propagation\n",
    "# on hidden layer\n",
    "Z1 = np.dot(X_train, W1)\n",
    "A1 = sigmoid(Z1)\n",
    "\n",
    "# on output layer\n",
    "Z2 = np.dot(A1, W2)\n",
    "A2 = sigmoid(Z2)\n",
    "    \n",
    "# Calculating error\n",
    "print('Meaned Squared Error :',mean_squared_error(A2, y_train))\n",
    "print('Accuracy :',accuracy(A2, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e794e765",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "#### Since we are able to achieve Actual Output in the Predicted Output of our Testing data , our model seems be correct and working"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f155fbeb9494e5ce992090b8427abe3542dae7719d8ea0d05cb0b78608edd18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
